{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c48397a4-1644-459a-be75-d98ddd99b07a",
   "metadata": {},
   "source": [
    "# Análisis Léxico (Scanner)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841aea63-71a7-4128-a7ca-79c7c4b55e8c",
   "metadata": {},
   "source": [
    "## Conceptos básicos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400623a1-662d-4ebe-9796-f16c6d631227",
   "metadata": {},
   "source": [
    "|             |                                               |\n",
    "| --          | --                                            |\n",
    "| **Entrada** | código fuente del LP que acepta el compilador |\n",
    "| **Salida**  | proporciona al parser los tokens              |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ef6faa-dc5e-4e15-a0bc-25e548f97c2f",
   "metadata": {},
   "source": [
    "## Token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c67fd6-6b28-485c-a2c8-481ce84b3f1b",
   "metadata": {},
   "source": [
    "* Es una agrupación de caracteres reconocidos por el scanner que constituyen los símbolos con los que se forman las sentencias del lenguaje\n",
    "* El scanner devuelve al parser el **nombre de ese símbolo junto con el valor del atributo**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487c335e-18d2-4076-8a90-f5a2ca366622",
   "metadata": {},
   "source": [
    "## Análisis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d91f12c-03d9-4d51-9afa-36f58474bfb9",
   "metadata": {},
   "source": [
    "* Una vez que empieza a leer el código fuente y reconoce el primer token, se lo envía al parser y este, en cuanto lo recibe, le pide el siguiente token para que siga reconociendo la entrada. Por tanto, los tokens son enviados al parser **bajo demanda**\n",
    "* Esta forma de funcionar se denomina **\"dirigida por la sintaxis\"** (parser driven)\n",
    "* Si reconoce un identificador lo almacena en la tabla de símbolos, y posteriormente, si el parser reconoce que ese identificador lleva asociada **información de tipo** (entero, real, etc.) o de valor, también agrega esta información a la mencionada tabla\n",
    "* En cuanto al sistema de gestión de errores, se encarga de **detectar símbolos que no pertenezcan a la gramática** porque no encajen con ningún patrón. Bien porque haya caracteres inválidos, ejemplo @, o bien porque se escriban mal las palabras reservadas del lenguaje"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e56bcd-b891-4d1d-9f9c-093e792e7ee9",
   "metadata": {},
   "source": [
    "## Funciones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d3efa7-103b-4030-8524-ba48ec59ae3d",
   "metadata": {},
   "source": [
    "1. Agrupar los caracteres que va leyendo uno a uno del programa fuente y formar los tokens\n",
    "1. Pasar los tokens válidos al parser\n",
    "1. Gestionar (abrir, leer y cerrar) el archivo que contiene el código fuente\n",
    "1. Eliminar comentarios, tabuladores, espacios en blanco, saltos de línea\n",
    "1. Relacionar los errores con las líneas del programa\n",
    "1. Expansión de macros\n",
    "1. Inclusión de archivos\n",
    "1. Reconocimientos de las directivas de compilación\n",
    "1. Introducir identificadores en la tabla de símbolos (opcional, pudiendo realizarse también por parte del parser)\n",
    "1. Dependiendo de la naturaleza del código fuente, podría ser necesario realizar una pasada previa para examinarlo y posteriormente procesarlo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4e1b08-6162-42e9-8010-259a0404e336",
   "metadata": {},
   "source": [
    "## Definiciones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8158ebb0-d3b5-4eb4-a4dd-8a42a2537976",
   "metadata": {},
   "source": [
    "||||\n",
    "| -- | -- | -- |\n",
    "| **Token o componente léxico** | agrupación de símbolos (símbolos terminales de GIC) con los que se forman las sentencias del lenguaje | palabras reservadas, identificadores, operadores, constantes, símbolos de puntuación y especiales |\n",
    "| **Lexema**                    | secuencia de caracteres, ya agrupados, que coinciden con un determinado token. Un token puede tener uno o infinitos lexemas | nombre de un identificador, valor de un número |\n",
    "| **Patrón**                    | es la forma de describir los tipos de lexemas. Se usan expresiones regulares (ER) | $[a-zA-Z] ([\\_] \\mid [a-zA-Z] \\mid [0-9])^*$ |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe4e6f3-15d2-4332-9daa-45610479bd34",
   "metadata": {},
   "source": [
    "## Ejemplos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efab19ce-52e3-4da2-8677-afd9ab0c06a6",
   "metadata": {},
   "source": [
    "| Token         | Lexema       | Patrón                 |\n",
    "| --            | --           | --                     |\n",
    "| While         | While        | $While$                |\n",
    "| Const         | const        | $const$                |\n",
    "| Suma          | +            | $+$                    |\n",
    "| Relación      | <, <=, !=    | $< \\mid <= \\mid !=$    |\n",
    "| Identificador | a, valor, b  | $[a-zA-Z]^+$           |\n",
    "| Número        | 5, 3, 25, 56 | $[0-9]^+(\\\\.[0-9]^+)?$ |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8a6da9-2ad3-4f79-88d5-dbe2b1abe450",
   "metadata": {},
   "source": [
    "## ¿Cómo funciona?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c1abcb-20c8-4442-b6db-7739db95c284",
   "metadata": {},
   "source": [
    "* El scanner funciona bajo demanda del parser cuando le pide el siguiente token\n",
    "* A partir del archivo que contiene el código fuente va leyendo caracteres que almacena en un buffer de entrada\n",
    "* Cuando encuentra un carácter que no le sirve para construir un token válido, se para y envía los caracteres acumulados al parser y espera una nueva petición de lectura de éste\n",
    "* Cuando recibe una nueva petición del parser limpia el buffer y vuelve a leer el carácter donde paró la vez anterior (ya que eso no pertenecía al token que envió)\n",
    "* Ejemplo:\n",
    "\n",
    "```c\n",
    "int x; \n",
    "main() {\n",
    "}\n",
    "  ```\n",
    "\n",
    "| ENTRADA     | BUFFER | ACCIÓN                                       |\n",
    "| --          | --     | --                                           |\n",
    "| i           | i      | Leer otro caracter                           |\n",
    "| n           | in     | Leer otro caracter                           |\n",
    "| t           | int    | Leer otro caracter                           |\n",
    "| blanco      | int    | Enviar token y limpiar buffer                |\n",
    "| x           | x      | Leer otro caracter                           |\n",
    "| ;           | x      | Enviar token y limpiar buffer                |\n",
    "| ...         | ...    | ...                                          |\n",
    "| Fin archivo | }      | Enviar token y finalizar proceso de análisis |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43225181-8ba7-439a-b78c-7489db125b72",
   "metadata": {},
   "source": [
    "## Diseño"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34cdadcd-f151-4cb6-9492-9c53b3966a1b",
   "metadata": {},
   "source": [
    "* Lo primero que tenemos que hacer para construir un scanner es diseñarlo, pudiendo usarse para ello una tabla o un diagrama de transición que representa los estados por los que va pasando el AF para reconocer un token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363d3610-bd93-48f2-88af-6a12e280939c",
   "metadata": {},
   "source": [
    "### Tabla de transiciones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee666657-2af4-48dd-8503-63ee7bf16781",
   "metadata": {},
   "source": [
    "| f      | a     | b     |\n",
    "| --     | --    | --    |\n",
    "| >$q_0$ | $q_1$ | -     |\n",
    "| *$q_1$ | $q_0$ | $q_1$ |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48df0adc-d747-47ae-aff5-15529a8fac52",
   "metadata": {},
   "source": [
    "### Diagrama de transiciones (DT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499a05ee-46cc-4650-abf9-4bc7266beecd",
   "metadata": {},
   "source": [
    "* Es una máquina de estados, parecida a un AFD pero con las siguientes diferencias:\n",
    "  * El AFD sólo dice si la secuencia de caracteres pertenece al lenguaje o no y el DT debe leer la secuencia hasta completar un token y luego retornar ese token y dejar la entrada preparada para leer el siguiente token\n",
    "  * En un DT cada secuencia no determinada es un error. En los AFD podía haber estados especiales de error o estados que englobaban secuencias no admitidas en otros estados\n",
    "  * Los estados de aceptación de los DT deben ser finales\n",
    "  * En un DT, cuando se lea un carácter que no pertenezca a ninguna secuencia especificada, se debe ir a un estado especial final y volver el cursor de lectura de caracteres al carácter siguiente a la secuencia correcta leída"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15f8d9b-04db-477d-85be-4a678b82c0dc",
   "metadata": {},
   "source": [
    "![AF](img/af.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19ccb15-cbdb-4155-a9a4-0166ac4fd7e7",
   "metadata": {},
   "source": [
    "## Ejemplo: Reconocimiento de identificadores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f40f049-2855-4bb2-996c-5b99f6ba3255",
   "metadata": {},
   "source": [
    "* Un identificador está formado por al menos una **letra mayúscula o minúscula** (ejemplo: a) seguida de forma opcional por mas letras o números (ejemplo: aa, a1, ...)\n",
    "* letra ::= $[a-zA-Z]$\n",
    "* número ::= $[0-9]$\n",
    "* otro ::= $[otro]$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261e2bed-ac2d-43cb-be9d-8126bebbfa56",
   "metadata": {},
   "source": [
    "![AF ID](img/af-id.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd033eb4-e7aa-4e6b-8182-b5d324a7e47b",
   "metadata": {},
   "source": [
    "## Ejemplo: Reconocimiento de números enteros sin signo, suma, incremento y producto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d5af3e-06ab-416e-b927-9afafecffb47",
   "metadata": {},
   "source": [
    "* Son válidos los siguientes lexemas: \"01\", \"32\", \"+\", \"++\", \"*\"\n",
    "* Patrones:\n",
    "  * ENTERO ::= $(0 | 1 | 2 | ... | 9)^+$\n",
    "  * SUMA ::= $+$\n",
    "  * PRODUCTO ::= $*$\n",
    "  * INCREMENTO ::= $++$\n",
    "* Un asterisco en un estado de aceptación indica que el puntero que señala la lectura del siguiente símbolo (para reconocer el siguiente token) debe retroceder una unidad (si hubiera más asteriscos, retrocedería tantas unidades como asteriscos)\n",
    "* Tras la llegada a un estado de aceptación, se le pasaría el token al parser y se esperaría una nueva petición de éste para comenzar otra vez en el estado 0 del autómata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4474934-5dea-4bb3-ab0e-1511f0d46910",
   "metadata": {},
   "source": [
    "![AF Aritmética](img/af-aritmetica.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156be2d5-8eca-4926-b21d-09f8e371db7d",
   "metadata": {},
   "source": [
    "| Q   | Dígito | $+$ | $*$ | Otro  | Token      | Retroceso |\n",
    "| --  | --     | --  | --  | --    | --         | --        |\n",
    "| >q0 | q5     | q2  | q1  | Error | -          | -         |\n",
    "| *q1 | -      | -   | -   | -     | PRODUCTO   | 0         |\n",
    "| q2  | q3     | q4  | q3  | q3    | -          | -         |\n",
    "| *q3 | -      | -   | -   | -     | SUMA       | 1         |\n",
    "| *q4 | -      | -   | -   | -     | INCREMENTO | 0         |\n",
    "| q5  | q5     | q6  | q6  | q6    | -          | -         |\n",
    "| *q6 | -      | -   | -   | -     | ENTERO     | 1         |\n",
    "\n",
    "* Una vez que se tiene la tabla, la implementación obtiene cada estado buscando el estado que hay en la fila correspondiente al estado actual y la entrada actual\n",
    "* Este proceso continúa hasta llegar a un estado de aceptación o uno de error\n",
    "* Si es de aceptación, devolverá el token junto con los caracteres acumulados hasta el momento\n",
    "* Si hay un retroceso en la fila, se retrocederá el cursor de selección de entrada tantas unidades como se indique en el retroceso\n",
    "* Se borra el buffer y se comienza en el estado 0\n",
    "* Si se ha llegado a un estado de error, se lanzará el error correspondiente\n",
    "\n",
    "* Suponer que se tiene  esta entrada: 25 + 5. El autómata efectuará estos pasos:\n",
    "    1. Estado=q0\n",
    "    2. Entrada=2\n",
    "    3. Estado=q5\n",
    "    4. Entrada=5\n",
    "    5. Estado=q5\n",
    "    6. Entrada=+\n",
    "    7. Estado=q6\n",
    "    8. Token=ENTERO\n",
    "    9. Lexema=25\n",
    "    10. Retroceso=1\n",
    "    11. Estado=q0\n",
    "    12. Entrada=+\n",
    "    13. Estado=q2\n",
    "    14. Entrada=5\n",
    "    15. Estado=q3\n",
    "    16. Token=SUMA\n",
    "    17. Lexema=+\n",
    "    18. Retroceso=1\n",
    "    19. Estado=q0\n",
    "    20. Entrada=5\n",
    "    21. Estado=q5\n",
    "    22. ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab43826-b2b5-4663-a77b-8eca2058771f",
   "metadata": {},
   "source": [
    "## Formas de implementar un scanner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97cfbf0e-5dd9-48d2-94f9-23943d476fd7",
   "metadata": {},
   "source": [
    "| Utilizando un ... | | Ventajas | Desventajas |\n",
    "| -- | -- | -- | -- |\n",
    "| **Generador de scanners**   | son herramientas que a partir de las ER generan un programa que permite reconocer los tokens o componentes léxicos. Suelen estar escritos en C (LEX) o Java (JFLEX) o Python (ply.lex) | comodidad y rapidez de desarrollo | programas ineficientes y dificultad de mantenimiento del código generado |\n",
    "| **Lenguaje de alto nivel** | a partir del diagrama de transiciones y del pseudocódigo correspondiente se programa un scanner | eficiente y compacto (lo que facilita el mantenimiento) | hay que realizarlo todo a mano |\n",
    "| **Lenguaje de bajo nivel (ensamblador)** | | más eficiente y compacto | más difícil de desarrollar |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c742d245-405b-43ef-950f-62f3138e267d",
   "metadata": {},
   "source": [
    "## Errores léxicos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34a594f-5414-4a36-bedc-0c3de75cbc6a",
   "metadata": {},
   "source": [
    "* Son detectados, cuando durante el proceso de reconocimiento de caracteres, los símbolos que tenemos en la entrada no concuerdan con ningún patrón. Hay que tener en cuenta que hay pocos errores detectables por el analizador léxico, entre ellos están:\n",
    "\n",
    "|                                                  |                                                                                                                        |\n",
    "| --                                               | --                                                                                                                     |\n",
    "| **Nombres incorrectos de los identificadores**   | se debe a que se utilizan caracteres inválidos para ese patrón. Ejemplos: un paréntesis, se empieza por un número      |\n",
    "| **Números incorrectos**                          | debido a que está escrito con caracteres inválidos (puntos en lugar de comas) o no está escrito correctamente          |\n",
    "| **Palabras reservadas escritas incorrectamente** | se producen errores de ortografía. El problema aquí es cómo distingues entre un identificador y una variable reservada |\n",
    "| **Caracteres que no pertenecen al alfabeto**     | Ejemplos: @, €, ¿, ?, ñ, etc.                                                                                          |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a46623b-21ab-4cd7-bce8-f933df3480bd",
   "metadata": {},
   "source": [
    "## Herramientas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2edadb-7f3d-4618-acfc-35f28622a242",
   "metadata": {},
   "source": [
    "|             |                                                                |                                                                                                    |\n",
    "| --          | --                                                             | --                                                                                                 |\n",
    "| **JLex**    | [https://www.jflex.de/](https://www.jflex.de/)                 |                                                                                                    |\n",
    "| **ply.lex** | [https://github.com/dabeaz/ply](https://github.com/dabeaz/ply) | [https://ply.readthedocs.io/en/latest/index.html](https://ply.readthedocs.io/en/latest/index.html) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3a7c3f-2229-4caa-8d48-e43c60299c7a",
   "metadata": {},
   "source": [
    "### Ejemplo JLex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fe9916-5240-4bf4-b0d4-6dd7bd7ae032",
   "metadata": {},
   "source": [
    "```java\n",
    "import java_cup.runtime.Symbol;\n",
    "\n",
    "%%\n",
    "%public\n",
    "%class Scanner\n",
    "%standalone\n",
    "%line\n",
    "%column\n",
    "%%\n",
    "\"+\" { return new Symbol(sym.MAS); }\n",
    "\"-\" { return new Symbol(sym.MENOS); }\n",
    "\"*\" { return new Symbol(sym.POR); }\n",
    "\"/\" { return new Symbol(sym.DIVISION); }\n",
    "\"(\" { return new Symbol(sym.LPAREN); }\n",
    "\")\" { return new Symbol(sym.RPAREN); }\n",
    "[:digit:]+ { return new Symbol(sym.NUMERO, new Integer(yytext())); }\n",
    "[ \\t\\r\\n]+ {;}\n",
    ". { System.out.println(\"Error léxico.\"+yytext()+\"-\"); }\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429ae266-71a3-47b3-8af3-8e4661c505e9",
   "metadata": {},
   "source": [
    "### Ejemplo ply.lex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4666de3-a50b-4fcd-a3fb-9ee49b6d97fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting calc.py\n"
     ]
    }
   ],
   "source": [
    "%%file calc.py\n",
    "import ply.lex as lex\n",
    "\n",
    "# definir tokens\n",
    "tokens  = ('PARIZQ', 'PARDER', 'MAS', 'MENOS', 'POR', 'DIVIDIDO', 'DECIMAL', 'ENTERO')\n",
    "\n",
    "# definir patrones\n",
    "t_PARIZQ    = r'\\('\n",
    "t_PARDER    = r'\\)'\n",
    "t_MAS       = r'\\+'\n",
    "t_MENOS     = r'-'\n",
    "t_POR       = r'\\*'\n",
    "t_DIVIDIDO  = r'/'\n",
    "\n",
    "def t_DECIMAL(t):\n",
    "    r'\\d+\\.\\d+'\n",
    "    try:\n",
    "        t.value = float(t.value)\n",
    "    except ValueError:\n",
    "        print(\"Float value too large %d\", t.value)\n",
    "        t.value = 0\n",
    "    return t\n",
    "\n",
    "def t_ENTERO(t):\n",
    "    r'\\d+'\n",
    "    try:\n",
    "        t.value = int(t.value)\n",
    "    except ValueError:\n",
    "        print(\"Integer value too large %d\", t.value)\n",
    "        t.value = 0\n",
    "    return t\n",
    "\n",
    "t_ignore = \" \\t\"\n",
    "\n",
    "def t_newline(t):\n",
    "    r'\\n+'\n",
    "    t.lexer.lineno += t.value.count(\"\\n\")\n",
    "    \n",
    "def t_error(t):\n",
    "    print(\"Illegal character '%s'\" % t.value[0])\n",
    "    t.lexer.skip(1)\n",
    "\n",
    "# construir scanner\n",
    "lexer = lex.lex()\n",
    "lexer.input('2 + 5X * [3)')\n",
    "while 1:\n",
    "    tok = lexer.token()\n",
    "    if not tok: break\n",
    "    print(tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4cd2c533-176b-41c3-871c-fa57eb77c77b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LexToken(ENTERO,2,1,0)\n",
      "LexToken(MAS,'+',1,2)\n",
      "LexToken(ENTERO,5,1,4)\n",
      "Illegal character 'X'\n",
      "LexToken(POR,'*',1,7)\n",
      "Illegal character '['\n",
      "LexToken(ENTERO,3,1,10)\n",
      "LexToken(PARDER,')',1,11)\n"
     ]
    }
   ],
   "source": [
    "!python calc.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
